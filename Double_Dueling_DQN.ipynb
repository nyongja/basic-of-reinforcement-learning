{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Double-Dueling-DQN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFAjDq/EomvxAnT3PdMMN3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyongja/basic-of-reinforcement-learning/blob/main/Double_Dueling_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGjUjNSJUbHh",
        "outputId": "058c1a1e-625d-488a-e0ed-01331865ea26"
      },
      "source": [
        "! pip install tensorflow==1.14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (53.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHg2qjOiVeNg",
        "outputId": "b83bfd46-c294-43d5-e969-792d7f7548e0"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3BMT4KueNF5",
        "outputId": "8a50451c-210a-4ea7-bd17-93bd4399c9e5"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.misc\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4RAlB9E_KLc"
      },
      "source": [
        "## 게임 환경 로딩\n",
        "환경을 로딩하고 설정하는 코드.  \n",
        "그리으듸 크기는 자유롭게 조절할 수 있음.  \n",
        "크기를 작게 하면 DQN 에이전트가 더 쉽게 작업을 수행할 것이며, 반대로 크게 하면 어려움이 배가 될 것임. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "rleWBzv6Bamx",
        "outputId": "85116a51-f71b-4593-ecbd-b345c01935df"
      },
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1a2d6876-e554-4226-a7f8-6373123176b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1a2d6876-e554-4226-a7f8-6373123176b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving gridworld.py to gridworld (1).py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb2LZXvdBe0h",
        "outputId": "b81fe3f1-dab6-4d3d-a61c-b0fd49df4c41"
      },
      "source": [
        "open('gridworld.py','wb').write(src)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4353"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWC2Bv2rDRm0",
        "outputId": "7306b20d-c22c-4d26-e5e0-ac87248f91fd"
      },
      "source": [
        "!pip install scipy==1.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUJ7bA4jDl_V"
      },
      "source": [
        "다음 그림은 환경 로딩 후 시작 환경의 예시.  \n",
        "에이전트는 파란색 블록을 위, 아래, 왼쪽, 오른쪽으로 이동함.  \n",
        "빨간색 블록(보상 - 1)을 피하여 초록색 블록(보상 + 1)에 도달해야 함.  \n",
        "세 가지 블록의 위치는 매 에피소드마다 랜덤하게 변함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "HAmY66d7_j1b",
        "outputId": "beb36970-a923-4342-c7b8-ec645da0548d"
      },
      "source": [
        "from gridworld import gameEnv\n",
        "\n",
        "env = gameEnv(partial = False, size = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SfjIOod_nPe"
      },
      "source": [
        "## 네트워크 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu-2fdhbDzD1"
      },
      "source": [
        "class QNetwork() :\n",
        "  def __init__(self, h_size) :\n",
        "    # 네트워크는 게임으로부터 하나의 프레임을 받아 이를 배열로 만듦(flattening)\n",
        "    # 그 다음 배열의 크기를 재조절하고 4개의 합성곱 계층을 거쳐 처리한다.\n",
        "\n",
        "    self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
        "    self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
        "    self.conv1 = slim.conv2d( \\\n",
        "        inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
        "    self.conv2 = slim.conv2d( \\\n",
        "        inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
        "    self.conv3 = slim.conv2d( \\\n",
        "        inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
        "    self.conv4 = slim.conv2d( \\\n",
        "        inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
        "    \n",
        "    # 마지막 합성곱 계층에서 출력값을 취한 후\n",
        "    # 이를 어드밴티지 스트림과 가치 스트림으로 분리\n",
        "    self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
        "    self.streamA = slim.flatten(self.streamAC)\n",
        "    self.streamV = slim.flatten(self.streamVC)\n",
        "    xavier_init = tf.contrib.layers.xavier_initializer()\n",
        "    self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
        "    self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
        "    self.Advantage = tf.matmul(self.streamA,self.AW)\n",
        "    self.Value = tf.matmul(self.streamV,self.VW)\n",
        "    \n",
        "    # 최종 Q 값을 얻기 위해 어드밴티지 스트림과 가치 스트림을 조합한다.\n",
        "    self.Qout = self.Value + tf.subtract(self.Advantage,\n",
        "                                         tf.reduce_mean(self.Advantage, axis = 1, keep_dims = True))\n",
        "    self.predict = tf.argmax(self.Qout, 1)\n",
        "\n",
        "    # 타깃 Q값과 예측 Q값의 차의 제곱합을 구함으로써 비용을 얻는다.\n",
        "    self.targetQ = tf.placeholder(shape = [None], dtype = tf.float32)\n",
        "    self.actions = tf.placeholder(shape = [None], dtype = tf.int32)\n",
        "    self.actions_onehot = tf.one_hot(self.actions, env.actions, dtype = tf.float32)\n",
        "\n",
        "    self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis = 1)\n",
        "\n",
        "    self.td_error = tf.square(self.targetQ - self.Q)\n",
        "    self.loss = tf.reduce_mean(self.td_error)\n",
        "    self.trainer = tf.train.AdamOptimizer(learning_rate = 0.0001)\n",
        "    self.updateModel = self.trainer.minimize(self.loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs5I1X6kF7Qh"
      },
      "source": [
        "## 경험 리플레이\n",
        "\n",
        "경험과 샘플을 저장하고 랜덤하게 네트워크를 학습시킴."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZzF7D4iF_Zl"
      },
      "source": [
        "class experience_buffer() :\n",
        "  def __init__(self, buffer_size = 50000) :\n",
        "    self.buffer = []\n",
        "    self.buffer_size = buffer_size\n",
        "  \n",
        "  def add(self,experience) :\n",
        "    if len(self.buffer) + len(experience) >= self.buffer_size :\n",
        "      self.buffer[0:(len(experience) + len(self.buffer)) - self.buffer_size] = []\n",
        "    self.buffer.extend(experience)\n",
        "\n",
        "  def sample(self, size) :\n",
        "    return np.reshape(np.array(random.sample(self.buffer, size)), [size, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzgnYGhsGVft"
      },
      "source": [
        "다음은 게임의 프레임의 크기를 재조절해주는 간단한 함수."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_CZQ04FGZRm"
      },
      "source": [
        "def processState(states) :\n",
        "  return np.reshape(states, [21168])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zc5itL2GcCm"
      },
      "source": [
        "다음 함수들은 1차 네트워크의 매개변수에 맞춰 타깃 네트워크의 매개변수를 업데이트하게 해줌."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7u0OFK5GgCv"
      },
      "source": [
        "def updateTargetGraph(tfVars,tau):\n",
        "  total_vars = len(tfVars)\n",
        "  op_holder = []\n",
        "  for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
        "      op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
        "  return op_holder\n",
        "\n",
        "def updateTarget(op_holder, sess) :\n",
        "  for op in op_holder :\n",
        "    sess.run(op)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q24EvFeGyrB"
      },
      "source": [
        "## 네트워크 학습\n",
        "\n",
        "학습 매개변수를 설정하는 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOv0OVNnG1W9"
      },
      "source": [
        "batch_size = 32 # 각 학습 단계에서 사용할 경험 배치의 수\n",
        "update_freq = 4 # 학습 단계 업데이트 빈도\n",
        "y = .99 # 타깃 Q 값에 대한 할인 계수\n",
        "startE = 1 # 랜덤한 액션을 시작할 가능성\n",
        "endE = 0.1 # 랜덤한 액션을 끝낼 가능성\n",
        "anneling_steps = 10000 # startE에서 endE로 줄어도는 데 필요한 학습 단계 수\n",
        "num_episodes = 10000 # 네트워크를 학습시키기 위한 게임 환경 에피소드의 수\n",
        "pre_train_steps = 10000 # 학습 시작 전 랜덤 액션의 단계 수\n",
        "max_epLength = 50 # 허용되는 최대 에피소드 길이\n",
        "load_model = False # 저장된 모델을 로드할지 여부\n",
        "path = \"./dqn\" # 모델을 저장할 경로\n",
        "h_size = 512 # 어드밴티지/가치 스트림으로 분리되기 전 마지막 합성곱 계층의 크기\n",
        "tau = 0.001 # 타깃 네트워크를 제 1 네트워크로 업데이트하는 비율"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls9ymgFeHZ7i"
      },
      "source": [
        "학습 과정을 구현한 코드는 다음과 같음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlazBEMqHcPC",
        "outputId": "45786dc6-ff85-42a7-bcbb-a3c8eca9dbee"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "mainQN = QNetwork(h_size)\n",
        "targetQN = QNetwork(h_size)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "trainables = tf.trainable_variables()\n",
        "targetOps = updateTargetGraph(trainables, tau)\n",
        "myBuffer = experience_buffer()\n",
        "\n",
        "# 랜덤 액션이 감소하는 비율을 설정\n",
        "e = startE\n",
        "stepDrop = (startE - endE) / anneling_steps\n",
        "\n",
        "# 보상의 총계와 에피소드별 단계 수를 담을 리스트를 생성함\n",
        "jList = []\n",
        "rList = []\n",
        "total_steps = 0\n",
        "\n",
        "# 모델을 저장할 경로를 생성함.\n",
        "if not os.path.exists(path) :\n",
        "  os.makedirs(path)\n",
        "\n",
        "with tf.Session() as sess :\n",
        "  sess.run(init)\n",
        "  if load_model == True :\n",
        "    prijnt('Loading Model...')\n",
        "    ckpt = tf.train.get_checkpoint_state(path)\n",
        "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "\n",
        "  # 타깃 네트워크가 제 1 네트워크와 동일하도록 설정\n",
        "  updateTarget(targetOps, sess)\n",
        "  for i in range(num_episodes) :\n",
        "    episodeBuffer = experience_buffer()\n",
        "    # 환경을 리셋하고 첫 번쨰 새로은 관찰을 얻는다.\n",
        "    s = env.reset()\n",
        "    s = processState(s)\n",
        "    d = False\n",
        "    rAll = 0\n",
        "    j = 0\n",
        "   # Q 네트워크\n",
        "   # 에이전트가 블록에 도달하기까지 최대 50회 시도하고 종료\n",
        "    while j < max_epLength :\n",
        "      j += 1 \n",
        "      # Q 네트워크에서 (e의 확률로 랜덤한 액션과 함께) 그리디하게 액션을 선택\n",
        "      if np.random.rand(1) < 3 or total_steps < pre_train_steps :\n",
        "        a = np.random.randint(0, 4)\n",
        "      else :\n",
        "        a = sess.run(mainQN.predict, feed_dict = {mainQN.scalarInput : [s]})[0]\n",
        "      s1, r, d = env.step(a)\n",
        "      s1 = processState(s1)\n",
        "      total_steps += 1\n",
        "      # 에피소드 버퍼에 경험을 저장\n",
        "      episodeBuffer.add(np.reshape(np.array([s, a, r, s1, d]), [1, 5]))\n",
        "\n",
        "      if total_steps > pre_train_steps :\n",
        "        if e > endE :\n",
        "          e -= stepDrop\n",
        "\n",
        "        if total_steps % (update_freq) == 0 :\n",
        "          # 경험에서 랜덤하게 배치 하나를 샘플링\n",
        "          trainBatch = myBuffer.sample(batch_size)\n",
        "          # 타깃 Q 값에 대해 더블 DQN 업데이트를 수행\n",
        "          Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
        "          Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
        "          end_multiplier = -(trainBatch[:,4] - 1)\n",
        "          doubleQ = Q2[range(batch_size),Q1]\n",
        "          targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
        "          # 타깃 값을 이용해 네트워크를 업데이트\n",
        "          _ = sess.run(mainQN.updateModel, \n",
        "                        feed_dict = {mainQN.scalarInput : np.vstack(trainBatch[:, 0]), \n",
        "                                    mainQN.targetQ : targetQ, mainQN.actions : trainBatch[:, 1]})\n",
        "          \n",
        "          # 타깃 네트워크가 제 1 네트워크와 동일하도록 설정\n",
        "          updateTarget(targetOps, sess)\n",
        "\n",
        "      rAll += r\n",
        "      s = s1\n",
        "\n",
        "      if d == True :\n",
        "        break\n",
        "    myBuffer.add(episodeBuffer.buffer)\n",
        "    jList.append(j)\n",
        "    rList.append(rAll)\n",
        "    # 정기적으로 모델 저장\n",
        "    if i % 1000 == 0 :\n",
        "      saver.save(sess, path + '/model-' + str(i) + '.cptk')\n",
        "      print(\"Saved Model\")\n",
        "    if len(rList) % 10 == 0 :\n",
        "      print(total_steps, np.mean(rList[-10 :]), e)\n",
        "\n",
        "  saver.save(sess, path + '/model-' + str(i) + '.cptk')\n",
        "print(\"Percent of succesful episodes : \" + str(sum(rList) / num_episodes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc03bb9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc03bb198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc03bb198>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc03bb198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc03bb198>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc03bb198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc03bb198>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc03bb198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc03bb198>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc06b49b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc06b49b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc06b49b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc06b49b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc06da860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc06da860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc06da860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadc06da860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadbff342b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadbff342b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadbff342b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadbff342b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadbfe3e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadbfe3e550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadbfe3e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fadbfe3e550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc040e6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc040e6a0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc040e6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc040e6a0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc040e6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc040e6a0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc040e6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fadc040e6a0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved Model\n",
            "500 2.2 1\n",
            "1000 2.3 1\n",
            "1500 1.6 1\n",
            "2000 2.2 1\n",
            "2500 2.8 1\n",
            "3000 1.8 1\n",
            "3500 2.1 1\n",
            "4000 1.3 1\n",
            "4500 1.5 1\n",
            "5000 1.9 1\n",
            "5500 3.4 1\n",
            "6000 1.9 1\n",
            "6500 3.2 1\n",
            "7000 2.1 1\n",
            "7500 1.9 1\n",
            "8000 0.5 1\n",
            "8500 2.2 1\n",
            "9000 2.2 1\n",
            "9500 0.9 1\n",
            "10000 2.1 1\n",
            "10500 3.0 0.9549999999999828\n",
            "11000 1.9 0.9099999999999655\n",
            "11500 2.1 0.8649999999999483\n",
            "12000 1.7 0.819999999999931\n",
            "12500 2.7 0.7749999999999138\n",
            "13000 1.6 0.7299999999998965\n",
            "13500 2.4 0.6849999999998793\n",
            "14000 1.7 0.639999999999862\n",
            "14500 2.0 0.5949999999998448\n",
            "15000 1.4 0.5499999999998275\n",
            "15500 3.5 0.5049999999998103\n",
            "16000 2.7 0.4599999999998177\n",
            "16500 2.2 0.41499999999982823\n",
            "17000 2.4 0.36999999999983874\n",
            "17500 2.7 0.32499999999984924\n",
            "18000 1.6 0.27999999999985975\n",
            "18500 1.6 0.23499999999986562\n",
            "19000 2.3 0.18999999999986225\n",
            "19500 2.0 0.14499999999985888\n",
            "20000 1.1 0.09999999999985551\n",
            "20500 1.5 0.09999999999985551\n",
            "21000 2.2 0.09999999999985551\n",
            "21500 1.1 0.09999999999985551\n",
            "22000 1.5 0.09999999999985551\n",
            "22500 3.4 0.09999999999985551\n",
            "23000 0.8 0.09999999999985551\n",
            "23500 1.4 0.09999999999985551\n",
            "24000 2.8 0.09999999999985551\n",
            "24500 1.0 0.09999999999985551\n",
            "25000 1.3 0.09999999999985551\n",
            "25500 2.2 0.09999999999985551\n",
            "26000 1.4 0.09999999999985551\n",
            "26500 3.5 0.09999999999985551\n",
            "27000 1.6 0.09999999999985551\n",
            "27500 0.9 0.09999999999985551\n",
            "28000 3.0 0.09999999999985551\n",
            "28500 1.7 0.09999999999985551\n",
            "29000 1.7 0.09999999999985551\n",
            "29500 2.2 0.09999999999985551\n",
            "30000 1.4 0.09999999999985551\n",
            "30500 3.2 0.09999999999985551\n",
            "31000 1.2 0.09999999999985551\n",
            "31500 1.1 0.09999999999985551\n",
            "32000 0.8 0.09999999999985551\n",
            "32500 2.3 0.09999999999985551\n",
            "33000 0.5 0.09999999999985551\n",
            "33500 2.8 0.09999999999985551\n",
            "34000 3.7 0.09999999999985551\n",
            "34500 3.3 0.09999999999985551\n",
            "35000 2.4 0.09999999999985551\n",
            "35500 2.4 0.09999999999985551\n",
            "36000 2.6 0.09999999999985551\n",
            "36500 1.2 0.09999999999985551\n",
            "37000 2.1 0.09999999999985551\n",
            "37500 2.9 0.09999999999985551\n",
            "38000 0.1 0.09999999999985551\n",
            "38500 1.7 0.09999999999985551\n",
            "39000 2.6 0.09999999999985551\n",
            "39500 1.2 0.09999999999985551\n",
            "40000 1.6 0.09999999999985551\n",
            "40500 1.3 0.09999999999985551\n",
            "41000 1.6 0.09999999999985551\n",
            "41500 1.1 0.09999999999985551\n",
            "42000 3.2 0.09999999999985551\n",
            "42500 2.3 0.09999999999985551\n",
            "43000 2.4 0.09999999999985551\n",
            "43500 1.1 0.09999999999985551\n",
            "44000 2.7 0.09999999999985551\n",
            "44500 2.3 0.09999999999985551\n",
            "45000 1.9 0.09999999999985551\n",
            "45500 2.3 0.09999999999985551\n",
            "46000 4.6 0.09999999999985551\n",
            "46500 1.3 0.09999999999985551\n",
            "47000 2.6 0.09999999999985551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "65GnackBIL9I",
        "outputId": "7b522c46-d97e-4d01-d509-0caf5a06400f"
      },
      "source": [
        "rMat = np.resize(np.array(rList), [len(rList) // 100, 100])\n",
        "rMean = np.average(rMat, 1)\n",
        "plt.plot(rMean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-de805915b9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrMat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrMean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrMat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrMean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G5knA3ALtO1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}